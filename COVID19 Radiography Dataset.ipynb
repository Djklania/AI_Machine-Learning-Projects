{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports\n"
      ],
      "metadata": {
        "id": "nwq7bXnhp_-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FwHIP_VtJ-WJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import random\n",
        "import zipfile\n",
        "import pathlib\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split-folders PyPI: Split folders with files (e.g. images) into train, validation and test (dataset) folders."
      ],
      "metadata": {
        "id": "pe_9hbUT6BY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders\n",
        "import splitfolders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87i9De8lhUhY",
        "outputId": "980bc04f-91a2-4fd1-93e3-4d84569b4f4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vOKquncvW1wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bb740b-aee9-41a3-da04-370f9aa1e4b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/Datasets/COVID-19_Radiography_Dataset.zip' .\n",
        "!unzip -q -n COVID-19_Radiography_Dataset.zip\n",
        "data_dir = '/content/COVID-19_Radiography_Dataset'\n",
        "#Dataset path = /content/COVID-19_Radiography_Dataset"
      ],
      "metadata": {
        "id": "9UmWKMkOtbwz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup some global variables\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (299,299)"
      ],
      "metadata": {
        "id": "xqDRrYh-9fZR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 Συνάρτηση prepare_datasets"
      ],
      "metadata": {
        "id": "TVCPPDQ7tAo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_datasets(data_dir, train_pct=0.6, val_pct=0.2, test_pct=0.2, batch_size=64, img_size=(299, 299)):\n",
        "    splitfolders.ratio(data_dir, output=\"/content/Data\", ratio=(train_pct, val_pct, test_pct))\n",
        "\n",
        "    # Get the subdirectories (classes)\n",
        "    data_dir = pathlib.Path('/content/Data/test')\n",
        "    classes = np.array(sorted(item.name for item in data_dir.glob(\"*\")))\n",
        "\n",
        "    # Test train validation split\n",
        "    test_dir = '/content/Data/test'\n",
        "    train_dir = '/content/Data/train'\n",
        "    val_dir = '/content/Data/val'\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "    train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "    valid_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "    test_ds = tf.keras.utils.image_dataset_from_directory(directory=test_dir,\n",
        "                                                          color_mode = 'grayscale',\n",
        "                                                          batch_size = BATCH_SIZE,\n",
        "                                                          image_size = IMG_SIZE,\n",
        "                                                          label_mode = 'categorical')\n",
        "\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(directory=train_dir,\n",
        "                                                           color_mode = 'grayscale',\n",
        "                                                           batch_size = BATCH_SIZE,\n",
        "                                                           image_size = IMG_SIZE,\n",
        "                                                           label_mode = 'categorical')\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(directory=val_dir,\n",
        "                                                         color_mode = 'grayscale',\n",
        "                                                         batch_size = BATCH_SIZE,\n",
        "                                                         image_size = IMG_SIZE,\n",
        "                                                         label_mode = 'categorical')\n",
        "\n",
        "    devel_ds = np.concatenate((train_ds, val_ds), axis=None)\n",
        "\n",
        "    return devel_ds, train_ds, val_ds, test_ds, classes"
      ],
      "metadata": {
        "id": "d_z680pVqjk6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Απλό συνελικτικό δίκτυο"
      ],
      "metadata": {
        "id": "C5tGjmznrnz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "devel_ds, train_ds, val_ds, test_ds, class_names = prepare_datasets(data_dir=\"/content/COVID-19_Radiography_Dataset\")"
      ],
      "metadata": {
        "id": "kJJH6ZXCN9kJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44122c89-2bc1-4555-bdb7-bb9b0ce484c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 21165 files [00:09, 2206.43 files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4235 files belonging to 4 classes.\n",
            "Found 12698 files belonging to 4 classes.\n",
            "Found 4232 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn1(num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(8,3,activation=\"relu\",input_shape = (299,299,3)),\n",
        "      tf.keras.layers.MaxPooling2D(strides = 2),\n",
        "      tf.keras.layers.Conv2D(16,3,activation=\"relu\",input_shape = (299,299,3)),\n",
        "      tf.keras.layers.MaxPooling2D(strides = 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(num_classes,activation=\"softmax\")\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JBK4nG_8rvlc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = cnn1(num_classes=4)"
      ],
      "metadata": {
        "id": "Ml4xEe_K7Nu0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model 1\n",
        "model_1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 10**-3,\n",
        "                                                     beta_1 = 0.9,\n",
        "                                                     beta_2 = 0.99 ),\n",
        "                loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "# Setup early callback\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor =\"loss\",patience = 3)\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_ds,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            steps_per_epoch = len(train_ds),\n",
        "            validation_data = val_ds,\n",
        "            validation_steps = len(val_ds),\n",
        "            epochs = 20,\n",
        "            callbacks = [callback])"
      ],
      "metadata": {
        "id": "BLcy1fz87RNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b538cf40-bce4-4b67-92a6-0062e0e0986d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "199/199 [==============================] - 59s 224ms/step - loss: 1.0773 - accuracy: 0.6661 - val_loss: 0.6983 - val_accuracy: 0.7339\n",
            "Epoch 2/20\n",
            "199/199 [==============================] - 42s 208ms/step - loss: 0.5343 - accuracy: 0.7948 - val_loss: 0.5002 - val_accuracy: 0.8086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Αξιολόγηση"
      ],
      "metadata": {
        "id": "u8xD9lQl-bVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_plot_confusion(model, dataset, class_names = class_names, pre_trained = False):\n",
        "    # Get predictions and labels\n",
        "    if pre_trained:\n",
        "        y_pred = model.predict(dataset)\n",
        "        pred = np.argmax(y_pred, axis = 1)\n",
        "        labels = np.argmax(dataset, axis = 1)\n",
        "    else:\n",
        "        pred = np.array([])\n",
        "        labels = np.array([])\n",
        "        for x , y in dataset:\n",
        "            pred = np.concatenate([pred, np.argmax(model.predict(x), axis=-1)])\n",
        "            labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n",
        "\n",
        "    # Create a confusion matrix\n",
        "    confusion =  tf.math.confusion_matrix(labels=labels, predictions=pred).numpy()\n",
        "\n",
        "    # Create multi class color plot for confusion matrix\n",
        "    label_conf = np.arange(confusion.shape[0])\n",
        "    fig , ax = plt.subplots(figsize=(16,16))\n",
        "    cax = ax.matshow(confusion, cmap=plt.cm.Blues)\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    ax.set(title=\"Confusion Matrix\",\n",
        "           xlabel=\"Predicted\",\n",
        "           ylabel=\"True\",\n",
        "           xticks = np.arange(len(class_names)),\n",
        "           yticks = np.arange(len(class_names)),\n",
        "           xticklabels = class_names,\n",
        "           yticklabels = class_names)\n",
        "    ax.xaxis.set_label_position(\"bottom\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    # Set the threshold for different colors\n",
        "    threshold = (confusion.max() + confusion.min()) / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(confusion.shape[0]), range(confusion.shape[1])):\n",
        "        plt.text(j, i, f\"{confusion[i, j]}\",\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if confusion[i, j] > threshold else \"black\",\n",
        "                size=14)"
      ],
      "metadata": {
        "id": "gU0TNFLqyF3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Training :{model_1.evaluate(train_ds)}\")\n",
        "print(f\" Testing  :{model_1.evaluate(test_ds)}\")\n",
        "print(f\" Valid    :{model_1.evaluate(val_ds)}\")"
      ],
      "metadata": {
        "id": "onHxKPVS-wDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_and_plot_confusion(model_1, test_ds)"
      ],
      "metadata": {
        "id": "y3AKoBgZ_b2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Συνελικτικό δίκτυο μεγαλύτερου βάθους"
      ],
      "metadata": {
        "id": "2q1N5m8-A0FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn2(num_classes):\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(32,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.Conv2D(32,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(strides = 4),\n",
        "\n",
        "      tf.keras.layers.Conv2D(64,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.Conv2D(64,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(strides = 2),\n",
        "\n",
        "      tf.keras.layers.Conv2D(128,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.Conv2D(128,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(strides = 2),\n",
        "\n",
        "      tf.keras.layers.Conv2D(256,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.Conv2D(256,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.Conv2D(256,3,input_shape = (224,224,3),activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(strides = 2),\n",
        "\n",
        "      tf.keras.layers.Conv2D(512, 3,input_shape = IMG_SIZE,activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(2),\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(num_classes,activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PfTpY5Zu_pOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_2 = cnn2(len(class_names))\n",
        "\n",
        "# Compile Model 2\n",
        "model_2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 10**-3,\n",
        "                                                     beta_1 = 0.9 ,\n",
        "                                                     beta_2 =0.99 ),\n",
        "                loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "# Setup early callback\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor =\"loss\",patience = 3)\n",
        "\n",
        "# Fit the model\n",
        "history_2 = model_2.fit(train_ds,\n",
        "                        steps_per_epoch = len(train_ds),\n",
        "                        epochs = 20,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        validation_data = val_ds,\n",
        "                        validation_steps = len(val_ds),\n",
        "                        callbacks = [callback])"
      ],
      "metadata": {
        "id": "m2GoovLrCGN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Training :{model_2.evaluate(train_ds)}\")\n",
        "print(f\" Testing  :{model_2.evaluate(test_ds)}\")\n",
        "print(f\" Valid    :{model_2.evaluate(val_ds)}\")"
      ],
      "metadata": {
        "id": "8Pnn4mzHCGUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_and_plot_confusion(model_2, test_ds)"
      ],
      "metadata": {
        "id": "lr3wohCSCIGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Με χρήση προεκπαιδευμένου δικτύου"
      ],
      "metadata": {
        "id": "OJYnYjEQCiWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change global variables\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224,244)\n",
        "\n",
        "# Test train validation split\n",
        "train_dir = '/content/Data/train'\n",
        "test_dir = '/content/Data/test'\n",
        "val_dir = '/content/Data/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "valid_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                                  target_size = IMG_SIZE,\n",
        "                                                  batch_size = BATCH_SIZE,\n",
        "                                                  class_mode = \"categorical\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                                target_size = IMG_SIZE,\n",
        "                                                batch_size = BATCH_SIZE,\n",
        "                                                class_mode = \"categorical\")\n",
        "\n",
        "val_data = valid_datagen.flow_from_directory(val_dir,\n",
        "                                                target_size = IMG_SIZE,\n",
        "                                                batch_size = BATCH_SIZE,\n",
        "                                                class_mode = \"categorical\")"
      ],
      "metadata": {
        "id": "cFH6cfapYGmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "# Create the efficientnet layer\n",
        "feature_extractor_layer  = hub.KerasLayer(model_url,\n",
        "                               trainable=False,\n",
        "                               input_shape = IMG_SIZE+(3,))\n",
        "\n",
        "output_size = len(class_names)\n",
        "\n",
        "# Now time to create our own model\n",
        "model_3  = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    tf.keras.layers.Dense(output_size,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile Model 3\n",
        "model_3.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 10**-3,\n",
        "                                                     beta_1 = 0.9 ,\n",
        "                                                     beta_2 =0.99 ),\n",
        "                loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "# Setup early callback\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor =\"loss\",patience = 3)\n",
        "\n",
        "# Fit the model\n",
        "history_3 = model_3.fit(train_data,\n",
        "                        epochs = 5,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        validation_data = val_data,\n",
        "                        callbacks = [callback])"
      ],
      "metadata": {
        "id": "NYjWqt2JCk-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Training :{model_3.evaluate(train_data)}\")\n",
        "print(f\" Testing  :{model_3.evaluate(test_data)}\")\n",
        "print(f\" Valid    :{model_3.evaluate(val_data)}\")"
      ],
      "metadata": {
        "id": "DMKG4lX5ErT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_and_plot_confusion(model_3, test_data, pre_trained = True)"
      ],
      "metadata": {
        "id": "PDkIEKTpEu07"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "F0BxjYaK2gw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NYt9xSRpsfYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "Z9Gjogr02bot"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Datasets/train.csv'\n",
        "test_path = '/content/drive/MyDrive/Datasets/test.csv'"
      ],
      "metadata": {
        "id": "QLjGBL0e_acg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Προετοιμασία δεδομένων"
      ],
      "metadata": {
        "id": "aXBJEjYK2ku3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir, test_dir, batch_size=64):\n",
        "  features = ['Title', 'Description']\n",
        "  target = 'Class Index'\n",
        "\n",
        "  train_df = pd.read_csv(data_dir, header = 0)\n",
        "  test_df = pd.read_csv(test_dir, header = 0)\n",
        "  train_df[target] = train_df[target] - 1\n",
        "  test_df[target] = test_df[target] -1\n",
        "\n",
        "  # Get size of unique values\n",
        "  n_labels = len(train_df['Class Index'].unique())\n",
        "\n",
        "  # Training Dataset\n",
        "  x_train = train_df.drop(target, axis=1)\n",
        "  y_train = train_df[target]\n",
        "\n",
        "  full_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "  test_size = int(0.8 * len(full_dataset))\n",
        "  raw_train_ds = full_dataset.take(test_size)\n",
        "  raw_val_ds = full_dataset.skip(test_size)\n",
        "\n",
        "  # Testing Dataset\n",
        "  x_test = test_df.drop(target, axis=1)\n",
        "  y_test = test_df[target]\n",
        "  raw_test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n",
        "  return raw_train_ds,raw_val_ds,raw_test_ds,n_labels"
      ],
      "metadata": {
        "id": "h6xm7x1I2oJo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Υλοποίηση μοντέλου με ενσωματώσεις λέξεων"
      ],
      "metadata": {
        "id": "Jd848jhM2olR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_ds, raw_val_ds, raw_test_ds, n_labels = load_data(data_dir = train_path,\n",
        "                                                            test_dir = test_path,\n",
        "                                                            batch_size = 32)"
      ],
      "metadata": {
        "id": "Xar26Bi38QLO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change input to lowercase, remove punctuation marks and also backslash (“\\”)\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  strip = tf.strings.regex_replace(lowercase, '\\\\', ' ')\n",
        "  return tf.strings.regex_replace(strip , '[%s]' % re.escape(string.punctuation), '')"
      ],
      "metadata": {
        "id": "nxCp2vsaPhpO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text,label):\n",
        "  text = tf.expand_dims(text - 1)\n",
        "  return custom_standardization(text),label"
      ],
      "metadata": {
        "id": "B3ju-sdCtUs_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional Api model\n",
        "input = tf.keras.Input(name = 'Title',shape=(None,),batch_size=64)\n",
        "input_2 = tf.keras.Input(name = 'Description',shape=(None,),batch_size=64)\n",
        "\n",
        "embedding = tf.keras.layers.Embedding(input_dim = 5000, input_length=250, output_dim=1)(input)\n",
        "\n",
        "embedding_2 = tf.keras.layers.Embedding(input_dim = 5000, input_length=250, output_dim=1)(input_2)\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=5000,\n",
        "    pad_to_max_tokens=True,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = 250)(embedding)\n",
        "\n",
        "vectorize_layer_2 = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=5000,\n",
        "    pad_to_max_tokens=True,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = 250)(embedding_2)\n",
        "\n",
        "global_average_pooling1d = tf.keras.layers.GlobalAveragePooling1D()(vectorize_layer)\n",
        "global_average_pooling1d_2 = tf.keras.layers.GlobalAveragePooling1D()(vectorize_layer_2)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(global_average_pooling1d)\n",
        "dense_1 = tf.keras.layers.Dense(64, activation='relu')(global_average_pooling1d_2)\n",
        "\n",
        "concatenate = tf.keras.layers.Concatenate([dense,dense_1])\n",
        "\n",
        "dropout = tf.keras.layers.Dropout(rate = 0.2,)(concatenate)\n",
        "\n",
        "dense_2 = tf.keras.layers.Dense(n_labels)(dropout)\n",
        "\n",
        "\n",
        "model = tf.keras.Model(inputs = [input, input_2],outputs = dense_2)"
      ],
      "metadata": {
        "id": "y_11E4tVAZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and fit the model\n",
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(raw_train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = raw_val_ds)"
      ],
      "metadata": {
        "id": "VgB3mvoYxFB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "print(f\" Training :{model.evaluate(raw_train_ds)}\")\n",
        "print(f\" Testing  :{model.evaluate(raw_test_ds)}\")\n",
        "print(f\" Valid    :{model.evaluate(raw_val_ds)}\")"
      ],
      "metadata": {
        "id": "8Vxih5hn8df7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}